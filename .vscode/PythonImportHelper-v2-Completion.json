[
    {
        "label": "fitz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fitz",
        "description": "fitz",
        "detail": "fitz",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "statistics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "statistics",
        "description": "statistics",
        "detail": "statistics",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "FileType",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "empty",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "util",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "concat",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "read_csv",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "zip",
        "importPath": "builtins",
        "description": "builtins",
        "isExtraImport": true,
        "detail": "builtins",
        "documentation": {}
    },
    {
        "label": "str",
        "importPath": "builtins",
        "description": "builtins",
        "isExtraImport": true,
        "detail": "builtins",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "cElementTree",
        "importPath": "xml.etree",
        "description": "xml.etree",
        "isExtraImport": true,
        "detail": "xml.etree",
        "documentation": {}
    },
    {
        "label": "pyxnat",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyxnat",
        "description": "pyxnat",
        "detail": "pyxnat",
        "documentation": {}
    },
    {
        "label": "get_document_styles",
        "kind": 2,
        "importPath": "Challenge_1a.main",
        "description": "Challenge_1a.main",
        "peekOfCode": "def get_document_styles(doc):\n    \"\"\"\n    Determines the most common font size in the document, likely the body text size.\n    Args:\n        doc: The PyMuPDF document object.\n    Returns:\n        The most frequent font size (rounded).\n    \"\"\"\n    font_sizes = defaultdict(int)\n    # Analyze a subset of pages for efficiency on very large documents",
        "detail": "Challenge_1a.main",
        "documentation": {}
    },
    {
        "label": "get_repetitive_lines",
        "kind": 2,
        "importPath": "Challenge_1a.main",
        "description": "Challenge_1a.main",
        "peekOfCode": "def get_repetitive_lines(doc):\n    \"\"\"\n    Identifies lines that are likely headers or footers by checking for repetition.\n    Args:\n        doc: The PyMuPDF document object.\n    Returns:\n        A set of repetitive text lines.\n    \"\"\"\n    line_count = defaultdict(int)\n    total_pages = len(doc)",
        "detail": "Challenge_1a.main",
        "documentation": {}
    },
    {
        "label": "extract_outline",
        "kind": 2,
        "importPath": "Challenge_1a.main",
        "description": "Challenge_1a.main",
        "peekOfCode": "def extract_outline(pdf_path):\n    \"\"\"\n    Main function to extract the title and a structured outline from a PDF.\n    This version uses a rule-based approach for identifying numbered headings.\n    Args:\n        pdf_path: Path to the PDF file.\n    Returns:\n        A dictionary containing the title and the outline.\n    \"\"\"\n    doc = fitz.open(pdf_path)",
        "detail": "Challenge_1a.main",
        "documentation": {}
    },
    {
        "label": "clean_text",
        "kind": 2,
        "importPath": "Challenge_1b.main",
        "description": "Challenge_1b.main",
        "peekOfCode": "def clean_text(text):\n    \"\"\"Cleans extracted PDF text.\"\"\"\n    ligatures = {\n        '\\ufb00': 'ff', '\\ufb01': 'fi', '\\ufb02': 'fl', '\\ufb03': 'ffi', '\\ufb04': 'ffl',\n        '\\u2022': '-', '\\u2013': '-', '\\u2014': '-',\n    }\n    for char, replacement in ligatures.items():\n        text = text.replace(char, replacement)\n    return ' '.join(text.split())\ndef extract_text_and_chunk(pdf_paths, base_dir):",
        "detail": "Challenge_1b.main",
        "documentation": {}
    },
    {
        "label": "extract_text_and_chunk",
        "kind": 2,
        "importPath": "Challenge_1b.main",
        "description": "Challenge_1b.main",
        "peekOfCode": "def extract_text_and_chunk(pdf_paths, base_dir):\n    \"\"\"\n    Extracts text and uses a more robust sliding-window chunking strategy.\n    \"\"\"\n    section_chunks = []\n    subsection_chunks = []\n    for pdf_path in pdf_paths:\n        file_path = base_dir / pdf_path\n        if not file_path.exists():\n            continue",
        "detail": "Challenge_1b.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "Challenge_1b.main",
        "description": "Challenge_1b.main",
        "peekOfCode": "def main():\n    if len(sys.argv) < 2:\n        print(\"Usage: python main.py <path_to_input.json>\", file=sys.stderr)\n        sys.exit(1)\n    input_path = Path(sys.argv[1])\n    base_dir = input_path.parent\n    with open(input_path, 'r', encoding='utf-8') as f:\n        input_data = json.load(f)\n    persona = input_data[\"persona\"][\"role\"]\n    job_to_be_done = input_data[\"job_to_be_done\"][\"task\"]",
        "detail": "Challenge_1b.main",
        "documentation": {}
    },
    {
        "label": "MODEL_NAME",
        "kind": 5,
        "importPath": "Challenge_1b.main",
        "description": "Challenge_1b.main",
        "peekOfCode": "MODEL_NAME = 'all-MiniLM-L6-v2'\nTOP_K_SECTIONS = 10\nTOP_K_SUBSECTIONS = 15\n# Keywords to find the most relevant content for the persona\nPOSITIVE_KEYWORDS = ['nightlife', 'bar', 'club', 'party', 'beach', 'budget', 'cheap', 'affordable', 'restaurant', 'hotel', 'hostel', 'activity', 'adventure', 'friends', 'group']\nKEYWORD_BOOST = 1.5 # How much to boost the score of chunks with keywords\ndef clean_text(text):\n    \"\"\"Cleans extracted PDF text.\"\"\"\n    ligatures = {\n        '\\ufb00': 'ff', '\\ufb01': 'fi', '\\ufb02': 'fl', '\\ufb03': 'ffi', '\\ufb04': 'ffl',",
        "detail": "Challenge_1b.main",
        "documentation": {}
    },
    {
        "label": "TOP_K_SECTIONS",
        "kind": 5,
        "importPath": "Challenge_1b.main",
        "description": "Challenge_1b.main",
        "peekOfCode": "TOP_K_SECTIONS = 10\nTOP_K_SUBSECTIONS = 15\n# Keywords to find the most relevant content for the persona\nPOSITIVE_KEYWORDS = ['nightlife', 'bar', 'club', 'party', 'beach', 'budget', 'cheap', 'affordable', 'restaurant', 'hotel', 'hostel', 'activity', 'adventure', 'friends', 'group']\nKEYWORD_BOOST = 1.5 # How much to boost the score of chunks with keywords\ndef clean_text(text):\n    \"\"\"Cleans extracted PDF text.\"\"\"\n    ligatures = {\n        '\\ufb00': 'ff', '\\ufb01': 'fi', '\\ufb02': 'fl', '\\ufb03': 'ffi', '\\ufb04': 'ffl',\n        '\\u2022': '-', '\\u2013': '-', '\\u2014': '-',",
        "detail": "Challenge_1b.main",
        "documentation": {}
    },
    {
        "label": "TOP_K_SUBSECTIONS",
        "kind": 5,
        "importPath": "Challenge_1b.main",
        "description": "Challenge_1b.main",
        "peekOfCode": "TOP_K_SUBSECTIONS = 15\n# Keywords to find the most relevant content for the persona\nPOSITIVE_KEYWORDS = ['nightlife', 'bar', 'club', 'party', 'beach', 'budget', 'cheap', 'affordable', 'restaurant', 'hotel', 'hostel', 'activity', 'adventure', 'friends', 'group']\nKEYWORD_BOOST = 1.5 # How much to boost the score of chunks with keywords\ndef clean_text(text):\n    \"\"\"Cleans extracted PDF text.\"\"\"\n    ligatures = {\n        '\\ufb00': 'ff', '\\ufb01': 'fi', '\\ufb02': 'fl', '\\ufb03': 'ffi', '\\ufb04': 'ffl',\n        '\\u2022': '-', '\\u2013': '-', '\\u2014': '-',\n    }",
        "detail": "Challenge_1b.main",
        "documentation": {}
    },
    {
        "label": "POSITIVE_KEYWORDS",
        "kind": 5,
        "importPath": "Challenge_1b.main",
        "description": "Challenge_1b.main",
        "peekOfCode": "POSITIVE_KEYWORDS = ['nightlife', 'bar', 'club', 'party', 'beach', 'budget', 'cheap', 'affordable', 'restaurant', 'hotel', 'hostel', 'activity', 'adventure', 'friends', 'group']\nKEYWORD_BOOST = 1.5 # How much to boost the score of chunks with keywords\ndef clean_text(text):\n    \"\"\"Cleans extracted PDF text.\"\"\"\n    ligatures = {\n        '\\ufb00': 'ff', '\\ufb01': 'fi', '\\ufb02': 'fl', '\\ufb03': 'ffi', '\\ufb04': 'ffl',\n        '\\u2022': '-', '\\u2013': '-', '\\u2014': '-',\n    }\n    for char, replacement in ligatures.items():\n        text = text.replace(char, replacement)",
        "detail": "Challenge_1b.main",
        "documentation": {}
    },
    {
        "label": "KEYWORD_BOOST",
        "kind": 5,
        "importPath": "Challenge_1b.main",
        "description": "Challenge_1b.main",
        "peekOfCode": "KEYWORD_BOOST = 1.5 # How much to boost the score of chunks with keywords\ndef clean_text(text):\n    \"\"\"Cleans extracted PDF text.\"\"\"\n    ligatures = {\n        '\\ufb00': 'ff', '\\ufb01': 'fi', '\\ufb02': 'fl', '\\ufb03': 'ffi', '\\ufb04': 'ffl',\n        '\\u2022': '-', '\\u2013': '-', '\\u2014': '-',\n    }\n    for char, replacement in ligatures.items():\n        text = text.replace(char, replacement)\n    return ' '.join(text.split())",
        "detail": "Challenge_1b.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "venv.bin.log2design",
        "description": "venv.bin.log2design",
        "peekOfCode": "def main(args):\n    runs_df = load_onsets(args.onsets_files, args)\n    print(\"Saving designfile (%d rows) to %s\" % (runs_df.shape[0], args.out))\n    runs_df.to_csv(args.out, index=False)\ndef load_onsets(onsets_files, args):\n    \"\"\"Read onsets file and add metadata from their filenames.\n    Return one concatenated pandas dataframe with all trials as rows.\"\"\"\n    runs = []\n    for i, fid in enumerate(onsets_files):\n        run = read_csv(fid)",
        "detail": "venv.bin.log2design",
        "documentation": {}
    },
    {
        "label": "load_onsets",
        "kind": 2,
        "importPath": "venv.bin.log2design",
        "description": "venv.bin.log2design",
        "peekOfCode": "def load_onsets(onsets_files, args):\n    \"\"\"Read onsets file and add metadata from their filenames.\n    Return one concatenated pandas dataframe with all trials as rows.\"\"\"\n    runs = []\n    for i, fid in enumerate(onsets_files):\n        run = read_csv(fid)\n        # If any column arguments were given, convert to a lyman-like design\n        # with explicitly named columns. Else, just concatenate and add 'run'.\n        if (args.onset_col or args.duration_col or args.condition_col or\n                args.pmods_col):",
        "detail": "venv.bin.log2design",
        "documentation": {}
    },
    {
        "label": "rename_columns",
        "kind": 2,
        "importPath": "venv.bin.log2design",
        "description": "venv.bin.log2design",
        "peekOfCode": "def rename_columns(args, run):\n    cols = ['run', 'onset', 'duration', 'condition']\n    # Cleanup any columns that might exist if we don't want them\n    if args.drop_cols:\n        for col in cols:\n            if col in run.columns:\n                run.drop(col, axis=1, inplace=True)\n    columns = {}\n    columns[args.onset_col] = 'onset'\n    columns[args.condition_col] = 'condition'",
        "detail": "venv.bin.log2design",
        "documentation": {}
    },
    {
        "label": "onsets_for",
        "kind": 2,
        "importPath": "venv.bin.log2design",
        "description": "venv.bin.log2design",
        "peekOfCode": "def onsets_for(cond, run_df):\n    \"\"\"\n    Inputs:\n      * Condition Label to grab onsets, durations & amplitudes for.\n      * Pandas Dataframe for current run containing onsets values as columns.\n    Outputs:\n      * Returns a dictionary of extracted values for onsets, durations, etc.\n      * Returns None if there are no onsets.\n    \"\"\"\n    condinfo = {}",
        "detail": "venv.bin.log2design",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "venv.bin.log2design",
        "description": "venv.bin.log2design",
        "peekOfCode": "def parse_args():\n    parser = ArgumentParser()\n    parser.add_argument('onsets_files', type=FileType('r'),\n                        help='List of FSL EV onsets to convert', nargs='+')\n    parser.add_argument('--out',   '-o', default='onsets_',\n                        help='Output filename.')\n    parser.add_argument('--verbose',      '-v', action=\"count\",\n                        help=\"increase output verbosity\")\n    parser.add_argument('--pmod-name', default='pmod',\n                        help='Name to use when writing FSL Amplitude as SPM '",
        "detail": "venv.bin.log2design",
        "documentation": {}
    },
    {
        "label": "cmp",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def cmp(a, b):\n    return (a > b) - (a < b)\nfrom builtins import zip\nfrom builtins import str\nimport os\nimport os.path as op\nimport sys\nfrom xml.etree import cElementTree as ET\nimport pyxnat\nPROJ_ATTRS = [",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "copy_attrs",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def copy_attrs(src_obj, dest_obj, attr_list):\n    \"\"\" Copies list of attributes form source to destination\"\"\"\n    src_attrs = src_obj.attrs.mget(attr_list)\n    src_list = dict(list(zip(attr_list, src_attrs)))\n    # NOTE: For some reason need to set te again b/c a bug somewhere sets te\n    # to sequence name\n    te_key = 'xnat:mrScanData/parameters/te'\n    if te_key in src_list:\n        src_list[te_key] = src_obj.attrs.get(te_key)\n    dest_obj.attrs.mset(src_list)",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "copy_attributes",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def copy_attributes(src_obj, dest_obj):\n    '''Copy attributes from src to dest'''\n    src_type = src_obj.datatype()\n    types = {'xnat:projectData': PROJ_ATTRS,\n             'xnat:subjectData': SUBJ_ATTRS,\n             'xnat:mrSessionData': MR_EXP_ATTRS,\n             'xnat:petSessionData': PET_EXP_ATTRS,\n             'xnat:ctSessionData': CT_EXP_ATTRS,\n             'xnat:mrScanData': MR_SCAN_ATTRS,\n             'xnat:petScanData': PET_SCAN_ATTRS,",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "subj_compare",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def subj_compare(item1, item2):\n    '''Compare sort of items'''\n    return cmp(item1.label(), item2.label())\ndef copy_file(src_f, dest_r, cache_d):\n    '''\n    Copy file from XNAT file source to XNAT resource destination,\n    using local cache in between'''\n    f_label = src_f.label()\n    loc_f = cache_d + '/' + f_label\n    # Make subdirectories",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "copy_file",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def copy_file(src_f, dest_r, cache_d):\n    '''\n    Copy file from XNAT file source to XNAT resource destination,\n    using local cache in between'''\n    f_label = src_f.label()\n    loc_f = cache_d + '/' + f_label\n    # Make subdirectories\n    loc_d = op.dirname(loc_f)\n    if not op.exists(loc_d):\n        os.makedirs(loc_d)",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "copy_res_zip",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def copy_res_zip(src_r, dest_r, cache_d):\n    '''\n    Copy a resource from XNAT source to XNAT destination using local cache\n    in between\n    '''\n    try:\n        # Download zip of resource\n        print('INFO:Downloading resource as zip...')\n        cache_z = src_r.get(cache_d, extract=False)\n        # Upload zip of resource",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "is_empty_resource",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def is_empty_resource(_res):\n    '''Check if resource contains any files'''\n    f_count = 0\n    for f_in in _res.files().fetchall('obj'):\n        f_count += 1\n        break\n    return f_count == 0\n# copy_project and copy_subject are untested\n# def copy_project(src_proj, dst_proj, proj_cache_dir):\n#     '''Copy XNAT project from source to destination'''",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "copy_session",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def copy_session(src_sess, dst_sess, sess_cache_dir):\n    '''Copy XNAT session from source to destination'''\n    print('INFO:uploading session attributes as xml')\n    # Write xml to file\n    if not op.exists(sess_cache_dir):\n        os.makedirs(sess_cache_dir)\n    sess_xml = src_sess.get()\n    xml_path = op.join(sess_cache_dir, 'sess.xml')\n    write_xml(sess_xml, xml_path)\n    sess_type = src_sess.datatype()",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "copy_scan",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def copy_scan(src_scan, dst_scan, scan_cache_dir):\n    '''Copy scan from source XNAT to destination XNAT'''\n    scan_type = src_scan.datatype()\n    if scan_type == '':\n        scan_type = 'xnat:otherDicomScanData'\n    dst_scan.create(scans=scan_type)\n    copy_attributes(src_scan, dst_scan)\n    # Process each resource of scan\n    for src_res in src_scan.resources().fetchall('obj'):\n        res_label = src_res.label()",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "copy_res",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def copy_res(src_res, dst_res, res_cache_dir, use_zip=False):\n    '''Copy resource from source XNAT to destination XNAT'''\n    # Create cache dir\n    if not op.exists(res_cache_dir):\n        os.makedirs(res_cache_dir)\n    # Prepare resource and check for empty\n    is_empty = False\n    print(dst_res._uri)\n    if not dst_res.exists():\n        dst_res.create()",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "write_xml",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def write_xml(xml_str, file_path, clean_tags=True):\n    \"\"\"Writing XML.\"\"\"\n    root = ET.fromstring(xml_str)\n    # We only want the tags and attributes relevant to root, no children\n    if clean_tags:\n        # Remove ID\n        if 'ID' in root.attrib:\n            del root.attrib['ID']\n        # Remove sharing tags\n        tag = '{http://nrg.wustl.edu/xnat}sharing'",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "create_parser",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def create_parser():\n    import argparse\n    \"\"\"Parse commandline arguments.\"\"\"\n    arg_parser = argparse.ArgumentParser(\n        description='Downloads a given experiment/session from an XNAT instance '\n                    'and uploads it to an independent one. Only DICOM resources '\n                    'will be imported.',\n        formatter_class=argparse.RawTextHelpFormatter)\n    arg_parser.add_argument(\n        '--h1', '--source_config', dest='source_config',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "def main(args):\n    x1 = pyxnat.Interface(config=args.source_config)\n    x2 = pyxnat.Interface(config=args.dest_config)\n    columns = ['subject_label', 'label']\n    e1 = x1.array.experiments(experiment_id=args.experiment_id,\n                              columns=columns).data[0]\n    p = x2.select.project(args.project_id)\n    s = p.subject(e1['subject_label'])\n    if not s.exists():\n        s.create()",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "PROJ_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "PROJ_ATTRS = [\n    'xnat:projectData/name',\n    'xnat:projectData/description',\n    'xnat:projectData/keywords',\n]\nSUBJ_ATTRS = [\n    'xnat:subjectData/group',\n    'xnat:subjectData/src',\n    'xnat:subjectData/investigator/firstname',\n    'xnat:subjectData/investigator/lastname',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "SUBJ_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "SUBJ_ATTRS = [\n    'xnat:subjectData/group',\n    'xnat:subjectData/src',\n    'xnat:subjectData/investigator/firstname',\n    'xnat:subjectData/investigator/lastname',\n    'xnat:subjectData/demographics[@xsi:type=xnat:demographicData]/dob',\n    'xnat:subjectData/demographics[@xsi:type=xnat:demographicData]/yob',\n    'xnat:subjectData/demographics[@xsi:type=xnat:demographicData]/age',\n    'xnat:subjectData/demographics[@xsi:type=xnat:demographicData]/gender',\n    'xnat:subjectData/demographics[@xsi:type=xnat:demographicData]/handedness',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "MR_EXP_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "MR_EXP_ATTRS = [\n    'xnat:experimentData/date',\n    'xnat:experimentData/visit_id',\n    'xnat:experimentData/time',\n    'xnat:experimentData/note',\n    'xnat:experimentData/investigator/firstname',\n    'xnat:experimentData/investigator/lastname',\n    'xnat:imageSessionData/scanner/manufacturer',\n    'xnat:imageSessionData/scanner/model',\n    'xnat:imageSessionData/operator',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "OTHER_DICOM_SCAN_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "OTHER_DICOM_SCAN_ATTRS = [\n    'xnat:imageScanData/type',\n    'xnat:imageScanData/UID',\n    'xnat:imageScanData/note',\n    'xnat:imageScanData/quality',\n    'xnat:imageScanData/condition',\n    'xnat:imageScanData/series_description',\n    'xnat:imageScanData/documentation',\n    'xnat:imageScanData/frames',\n    'xnat:imageScanData/startTime',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "MR_SCAN_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "MR_SCAN_ATTRS = [\n    'xnat:imageScanData/type',\n    'xnat:imageScanData/UID',\n    'xnat:imageScanData/note',\n    'xnat:imageScanData/quality',\n    'xnat:imageScanData/condition',\n    'xnat:imageScanData/series_description',\n    'xnat:imageScanData/documentation',\n    'xnat:imageScanData/frames',\n    'xnat:imageScanData/startTime',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "SC_SCAN_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "SC_SCAN_ATTRS = [\n    'xnat:imageScanData/type',\n    'xnat:imageScanData/UID',\n    'xnat:imageScanData/note',\n    'xnat:imageScanData/quality',\n    'xnat:imageScanData/condition',\n    'xnat:imageScanData/series_description',\n    'xnat:imageScanData/documentation',\n    'xnat:imageScanData/frames',\n    'xnat:imageScanData/scanner/manufacturer',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "PET_EXP_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "PET_EXP_ATTRS = [\n    'xnat:experimentData/date',\n    'xnat:experimentData/visit_id',\n    'xnat:experimentData/time',\n    'xnat:experimentData/note',\n    'xnat:experimentData/investigator/firstname',\n    'xnat:experimentData/investigator/lastname',\n    'xnat:imageSessionData/scanner/manufacturer',\n    'xnat:imageSessionData/scanner/model',\n    'xnat:imageSessionData/operator',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "CT_EXP_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "CT_EXP_ATTRS = [\n    'xnat:experimentData/date',\n    'xnat:experimentData/visit_id',\n    'xnat:experimentData/time',\n    'xnat:experimentData/note',\n    'xnat:experimentData/investigator/firstname',\n    'xnat:experimentData/investigator/lastname',\n    'xnat:imageSessionData/scanner/manufacturer',\n    'xnat:imageSessionData/scanner/model',\n    'xnat:imageSessionData/operator',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "PET_SCAN_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "PET_SCAN_ATTRS = [\n    'xnat:imageScanData/type',\n    'xnat:imageScanData/UID',\n    'xnat:imageScanData/note',\n    'xnat:imageScanData/quality',\n    'xnat:imageScanData/condition',\n    'xnat:imageScanData/series_description',\n    'xnat:imageScanData/documentation',\n    'xnat:imageScanData/frames',\n    'xnat:imageScanData/scanner/manufacturer',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "CT_SCAN_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "CT_SCAN_ATTRS = [\n    'xnat:imageScanData/type',\n    'xnat:imageScanData/UID',\n    'xnat:imageScanData/note',\n    'xnat:imageScanData/quality',\n    'xnat:imageScanData/condition',\n    'xnat:imageScanData/series_description',\n    'xnat:imageScanData/documentation',\n    'xnat:imageScanData/frames',\n    'xnat:imageScanData/scanner/manufacturer',",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    },
    {
        "label": "PROC_ATTRS",
        "kind": 5,
        "importPath": "venv.bin.sessionmirror",
        "description": "venv.bin.sessionmirror",
        "peekOfCode": "PROC_ATTRS = [\n    'proc:genProcData/validation/status',\n    'proc:genProcData/procstatus',\n    'proc:genProcData/proctype',\n    'proc:genProcData/procversion',\n    'proc:genProcData/walltimeused',\n    'proc:genProcData/memused'\n]\ndef copy_attrs(src_obj, dest_obj, attr_list):\n    \"\"\" Copies list of attributes form source to destination\"\"\"",
        "detail": "venv.bin.sessionmirror",
        "documentation": {}
    }
]